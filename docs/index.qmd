---
title: omeka2dsp Documentation
date-modified: last-modified
---

Complete documentation for the Omeka to DaSCH Service Platform (DSP) data migration tool.

## ðŸ“š Core Documentation

-   ðŸ—ï¸ [**System Architecture**](architecture/index.qmd) -- Overview of system components, design patterns, and data flow architecture with class diagrams illustrating core components and their interactions.
-   ðŸ”„ [**Data Migration Workflows**](workflows/index.qmd) -- Complete workflow documentation with Mermaid diagrams covering the main migration workflow (end-to-end process), data extraction workflow (Omeka API interaction), data transformation workflow (format conversion), synchronization workflow (incremental updates), file upload workflow (media processing) and error handling workflow (recovery and retry)
-   ðŸ”§ [**API Reference**](api/index.qmd) -- Comprehensive documentation of all 5 Python modules with 50+ functions
- ðŸ§© [**Data Model**](/docs/datamodel/index.qmd) -- Data model documentation

## ðŸ“’ Guides

-   âš¡ [**Installation & Setup**](guides/installation.qmd) -- How to install and configure the system
-   âš™ï¸ [**Configuration**](guides/configuration.qmd) -- Environment variables and settings
-   ðŸ“‹ [**Usage**](guides/usage.qmd) -- How to run the migration scripts
-   ðŸ› ï¸ [**Development**](guides/development.qmd) -- Contributing and extending the codebase
-   ðŸ” [**Troubleshooting**](guides/troubleshooting.qmd) -- Common issues and solutions

## ðŸš€ Quick Start

1.  **Setup Environment**: Configure your environment variables (see [Configuration Guide](guides/configuration.qmd))
2.  **Install Dependencies**: Install required Python packages
3.  **Run Migration**: Execute the data transfer script

``` bash
# Set up environment variables
cp example.env .env
# Edit .env with your configuration

# Run the migration
uv run python scripts/data_2_dasch.py
```

## System Overview

The omeka2dsp system transfers research data from [Stadt.Geschichte.Basel (SGB)](https://stadtgeschichtebasel.ch/)'s Omeka instance to the [DaSCH Service Platform (DSP)](https://www.dasch.swiss/plattform-characteristics) for long-term preservation.

### Features

-   âœ… **Full Data Migration** -- Transfer metadata and media files
-   âœ… **Incremental Sync** -- Update existing resources with changes
-   âœ… **Multiple Modes** -- Process all data, samples, or test data
-   âœ… **Error Handling** -- Comprehensive logging and error recovery
-   âœ… **Configuration** -- Flexible environment-based configuration

### Key Components

```{mermaid}
graph LR
    A[Omeka API] --> B[data_2_dasch.py]
    B --> C[DSP API]
    B --> D[File Storage]
    
    E[process_data_from_omeka.py] --> B
    F[Configuration] --> B
    
    style A fill:#e1f5fe
    style C fill:#e8f5e8
    style B fill:#fff3e0
```

### Main Scripts

-   **`data_2_dasch.py`** -- Main migration script with sync capabilities
-   **`process_data_from_omeka.py`** -- Omeka API data extraction utilities
-   **`api_get_project.py`** -- Fetch DSP project information
-   **`api_get_lists.py`** -- Retrieve DSP list configurations
-   **`api_get_lists_detailed.py`** -- Get detailed list metadata

For detailed API documentation, see [API Reference](api/index.qmd).

### Architecture

The system follows a modular architecture with clear separation of concerns:

-   **Data Extraction Layer** -- Interfaces with Omeka API
-   **Transformation Layer** -- Converts data formats between systems
-   **Upload Layer** -- Manages file transfers and API interactions
-   **Synchronization Layer** -- Handles incremental updates and conflict resolution

For detailed architecture documentation, see [System Architecture](architecture/index.qmd).